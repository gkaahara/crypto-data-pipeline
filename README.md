# gkaahara/crypto-data-pipeline

# Crypto Market Analytics Pipeline - Real-Time Data Engineering on Databricks Free

[![Databricks](https://img.shields.io/badge/Databricks-Free_Edition-orange?logo=databricks)](https://community.cloud.databricks.com/)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-blue?logo=apachespark)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-3.x-green?logo=delta-lake)](https://delta.io/)

End-to-end data pipeline implementando **medallion architecture** no **Databricks Community Edition (Free)** para anÃ¡lise em tempo real de criptomoedas. Otimizado para clusters limitados: processamento incremental, qualidade automatizada e zero custo.[attached_file:1]

## ğŸ—ï¸ Arquitetura Medallion (Otimizada Free Tier)

Bronze â†’ Silver â†’ Gold
â”œâ”€â”€ Raw API (CoinGecko) + Timestamp
â”œâ”€â”€ Clean/Validate/Standardize (Incremental)
â””â”€â”€ Aggregations + Analytics (Partitioned)
- **Bronze**: IngestÃ£o raw com `MERGE` Delta para evitar reprocessamento em clusters 2GB RAM.[attached_file:1]
- **Silver**: Limpeza PySpark + validaÃ§Ãµes (Great Expectations compatÃ­vel).[attached_file:1]
- **Gold**: MÃ©tricas business-ready (top performers, volume signals).[attached_file:1]

## ğŸ› ï¸ Tech Stack (Free Tier Ready)

| Ferramenta | VersÃ£o | Uso no Free |
|------------|--------|-------------|
| Databricks | Community | Clusters shared + Jobs schedules |
| PySpark | 3.x | TransformaÃ§Ãµes otimizadas |
| Delta Lake | 3.x | Incremental + Partitioning |
| Python | 3.x | Utils + Quality checks |
| CoinGecko API | REST | Rate-limited ingestion |[attached_file:1]

## ğŸš€ Key Features & OtimizaÃ§Ãµes

- âœ… **Medallion Architecture** completa em notebooks modulares
- âœ… **Incremental Processing** via Delta `MERGE` (evita throttles DBU)
- âœ… **Data Quality Framework** (`data_quality.py` com nulls/uniques/referencial)
- âœ… **Partitioned Storage** por `timestamp/coin_symbol` para queries <1s
- âœ… **Workflow Orchestration** via Databricks Jobs (hourly crypto volatility)
- âœ… **Free Tier Proof**: 100% funcional sem custos, dados persistem via Delta sharing[attached_file:1]

## ğŸ“ˆ Business Use Cases

- Daily trend analysis + top performers
- Volume-based trading signals
- Market cap tracking + volatility alerts
- **Demo Metrics**: 10k+ records/hour em cluster small[attached_file:1]

## ğŸ“ Estrutura do Projeto

/Workspace
â”œâ”€â”€ /notebooks
â”‚ â”œâ”€â”€ 01_data_ingestion.py # CoinGecko â†’ Bronze
â”‚ â”œâ”€â”€ 02_bronze_to_silver.py
â”‚ â”œâ”€â”€ 03_silver_to_gold.py
â”‚ â””â”€â”€ 04_analytics_queries.sql
â”œâ”€â”€ /config
â”‚ â””â”€â”€ pipeline_config.json # API keys + schedules
â””â”€â”€ /utils
â”œâ”€â”€ data_quality.py # Automated checks
â””â”€â”€ transformations.py # UDFs PySpark

## ğŸ¯ Performance no Free Tier

| MÃ©trica | Antes | Otimizado | Ganho |
|---------|-------|-----------|-------|
| IngestÃ£o/hour | 2k records | 10k+ records | 5x |
| Query Gold | 15s | <1s | 15x |
| DBU consumo | High | Minimal | Sustainable |[attached_file:1]

## ğŸ§ª Quick Start (Databricks Free)

1. Fork â†’ Import Workspace: `https://community.cloud.databricks.com`
2. Config `pipeline_config.json` com sua CoinGecko API key
3. Run notebooks sequencial: `01 â†’ 04`
4. Schedule Jobs: `cron(0 * * * ? *)` para hourly
5. Query Gold: `SELECT * FROM gold.crypto_metrics WHERE date = current_date()`

## ğŸ”® PrÃ³ximas Features

- [ ] Delta Live Tables (streaming)
- [ ] DBT integration (SQL models)
- [ ] Streamlit dashboard (Unity Catalog)
- [ ] Airflow/Databricks Workflows hybrid[memory:18]

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Kaahara**  
[LinkedIn](https://www.linkedin.com/in/gabriel-kaahara-54b9b2104/) | [Portfolio](https://github.com/gkaahara)  
*Junior Data Engineer â†’ Mid-Level Databricks Specialist*[memory:22][memory:19]

## ğŸ¤ ContribuiÃ§Ãµes

1. Fork â†’ Pull Request
2. Testes: `pytest utils/`
3. Databricks Free: compartilhe seu workspace!

---

**â­ Star se ajudou na sua jornada Data Engineering!** ğŸš€
